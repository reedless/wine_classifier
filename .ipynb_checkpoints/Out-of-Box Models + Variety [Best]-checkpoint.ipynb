{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
       "\n",
       "              variety  \n",
       "0  Cabernet Sauvignon  \n",
       "1       Tinta de Toro  \n",
       "2     Sauvignon Blanc  \n",
       "3          Pinot Noir  \n",
       "4  Provence red blend  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick out features X and labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,2:4].values\n",
    "y = df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 96., 235.],\n",
       "        [ 96., 110.],\n",
       "        [ 96.,  90.],\n",
       "        ...,\n",
       "        [ 91.,  20.],\n",
       "        [ 90.,  52.],\n",
       "        [ 90.,  15.]]), 0        US\n",
       " 1     Spain\n",
       " 2        US\n",
       " 3        US\n",
       " 4    France\n",
       " Name: country, dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91. 38.]\n",
      " [89. 50.]\n",
      " [87. 38.]\n",
      " ...\n",
      " [83. 14.]\n",
      " [86. 30.]\n",
      " [83. 38.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102104        US\n",
       "39339         US\n",
       "57198         US\n",
       "28598      Italy\n",
       "85027     France\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise models\n",
    "LR_model         = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "LDA_model        = LinearDiscriminantAnalysis()\n",
    "KNN_model        = KNeighborsClassifier()\n",
    "GaussianNB_model = GaussianNB()\n",
    "DTree_model      = DecisionTreeClassifier()\n",
    "SVC_model        = LinearSVC(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(booster='gbtree', objective='multi:softprob', random_state=42, eval_metric=\"auc\", num_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandFC_model = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, eval_metric='auc', gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, num_class=4, objective='multi:softprob',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandFC_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_test\n",
    "test_labels = y_test\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(test_set)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(test_set)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(test_set)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(test_set)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(test_set)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(test_set)\n",
    "list_of_predictions.append(SVC_prediction)\n",
    "\n",
    "XGB_prediction   = xgb_model.predict(test_set)\n",
    "list_of_predictions.append(XGB_prediction)\n",
    "\n",
    "RandFC_prediction = RandFC_model.predict(test_set)\n",
    "list_of_predictions.append(RandFC_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598408266743686\n",
      "0.5987291807066526\n",
      "0.5256891627354706\n",
      "0.5945893905843843\n",
      "0.6076505888771221\n",
      "0.46086454221623185\n",
      "0.6007509386733417\n",
      "0.6026122396585475\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   77    20     8    14]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [ 4377  5648  2447 18570]]\n",
      "[[  103    31    16    30]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [ 4351  5637  2439 18554]]\n",
      "[[  963   918   366  1732]\n",
      " [  738  1149   437  2150]\n",
      " [  223   209   284   717]\n",
      " [ 2530  3392  1368 13985]]\n",
      "[[  426   276   103   488]\n",
      " [   33    40     5    34]\n",
      " [    0     0     0     0]\n",
      " [ 3995  5352  2347 18062]]\n",
      "[[  419   162    65   223]\n",
      " [  256   575    98   425]\n",
      " [   18    29    88    83]\n",
      " [ 3761  4902  2204 17853]]\n",
      "[[    0     0     0     0]\n",
      " [ 1418  1616   660  5839]\n",
      " [    0     0     0     0]\n",
      " [ 3036  4052  1795 12745]]\n",
      "[[  229    90    50   108]\n",
      " [    2    14     1     3]\n",
      " [    2     2    13     9]\n",
      " [ 4221  5562  2391 18464]]\n",
      "[[  250    87    56   128]\n",
      " [   60   168    24    89]\n",
      " [   14    18    63    70]\n",
      " [ 4130  5395  2312 18297]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.02      0.65      0.03       119\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     31042\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     31161\n",
      "   macro avg       0.25      0.31      0.20     31161\n",
      "weighted avg       1.00      0.60      0.75     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.02      0.57      0.04       180\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     30981\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     31161\n",
      "   macro avg       0.26      0.29      0.20     31161\n",
      "weighted avg       0.99      0.60      0.74     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.22      0.24      0.23      3979\n",
      "       Italy       0.20      0.26      0.23      4474\n",
      "       Spain       0.12      0.20      0.15      1433\n",
      "          US       0.75      0.66      0.70     21275\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     31161\n",
      "   macro avg       0.32      0.34      0.33     31161\n",
      "weighted avg       0.58      0.53      0.55     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.10      0.33      0.15      1293\n",
      "       Italy       0.01      0.36      0.01       112\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.61      0.75     29756\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     31161\n",
      "   macro avg       0.27      0.32      0.23     31161\n",
      "weighted avg       0.93      0.59      0.72     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.09      0.48      0.16       869\n",
      "       Italy       0.10      0.42      0.16      1354\n",
      "       Spain       0.04      0.40      0.07       218\n",
      "          US       0.96      0.62      0.75     28720\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     31161\n",
      "   macro avg       0.30      0.48      0.29     31161\n",
      "weighted avg       0.89      0.61      0.71     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.00      0.00      0.00         0\n",
      "       Italy       0.29      0.17      0.21      9533\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.69      0.59      0.63     21628\n",
      "\n",
      "   micro avg       0.46      0.46      0.46     31161\n",
      "   macro avg       0.24      0.19      0.21     31161\n",
      "weighted avg       0.56      0.46      0.51     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.05      0.48      0.09       477\n",
      "       Italy       0.00      0.70      0.00        20\n",
      "       Spain       0.01      0.50      0.01        26\n",
      "          US       0.99      0.60      0.75     30638\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     31161\n",
      "   macro avg       0.26      0.57      0.21     31161\n",
      "weighted avg       0.98      0.60      0.74     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.06      0.48      0.10       521\n",
      "       Italy       0.03      0.49      0.06       341\n",
      "       Spain       0.03      0.38      0.05       165\n",
      "          US       0.98      0.61      0.75     30134\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     31161\n",
      "   macro avg       0.27      0.49      0.24     31161\n",
      "weighted avg       0.95      0.60      0.73     31161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_train\n",
    "test_labels = y_train\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(test_set)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(test_set)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(test_set)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(test_set)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(test_set)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(test_set)\n",
    "list_of_predictions.append(SVC_prediction)\n",
    "\n",
    "XGB_prediction   = xgb_model.predict(test_set)\n",
    "list_of_predictions.append(XGB_prediction)\n",
    "\n",
    "RandFC_prediction = RandFC_model.predict(test_set)\n",
    "list_of_predictions.append(RandFC_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6011938327808877\n",
      "0.6015101709601551\n",
      "0.5401955795177906\n",
      "0.5974252822974404\n",
      "0.6223472292901646\n",
      "0.46266521792949783\n",
      "0.6046047835834238\n",
      "0.6093361024385547\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US        18584\n",
       "Italy      5668\n",
       "France     4454\n",
       "Spain      2455\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  183    59    11    27]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [10148 13057  5694 43528]]\n",
      "[[  242    90    23    63]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [10089 13026  5682 43492]]\n",
      "[[ 2503  1942   802  3967]\n",
      " [ 1593  2851  1021  4716]\n",
      " [  475   501   696  1646]\n",
      " [ 5760  7822  3186 33226]]\n",
      "[[ 1004   708   209  1101]\n",
      " [   53    86    18   107]\n",
      " [    0     0     0     0]\n",
      " [ 9274 12322  5478 42347]]\n",
      "[[ 1187   296   111   327]\n",
      " [  509  1576   221   871]\n",
      " [   42    59   242   113]\n",
      " [ 8593 11185  5131 42244]]\n",
      "[[    0     0     0     0]\n",
      " [ 3430  3796  1568 13712]\n",
      " [    0     0     0     0]\n",
      " [ 6901  9320  4137 29843]]\n",
      "[[  532   235    98   169]\n",
      " [   12    33     2     7]\n",
      " [    1     6    31    16]\n",
      " [ 9786 12842  5574 43363]]\n",
      "[[  649   226   114   211]\n",
      " [  134   459    56   200]\n",
      " [   36    57   149    98]\n",
      " [ 9512 12374  5386 43046]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.01      0.68      0.03        65\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     20709\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.25      0.32      0.20     20774\n",
      "weighted avg       1.00      0.60      0.75     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.02      0.56      0.04       102\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     20672\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.25      0.29      0.20     20774\n",
      "weighted avg       0.99      0.60      0.75     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.18      0.27      0.22      1993\n",
      "       Italy       0.21      0.29      0.25      2711\n",
      "       Spain       0.08      0.17      0.11       745\n",
      "          US       0.80      0.65      0.71     15325\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     20774\n",
      "   macro avg       0.32      0.34      0.32     20774\n",
      "weighted avg       0.64      0.55      0.58     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.10      0.36      0.16       805\n",
      "       Italy       0.01      0.34      0.01        79\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.61      0.75     19890\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.27      0.33      0.23     20774\n",
      "weighted avg       0.94      0.60      0.72     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.08      0.51      0.14       488\n",
      "       Italy       0.09      0.41      0.15       821\n",
      "       Spain       0.03      0.33      0.06       165\n",
      "          US       0.97      0.62      0.76     19300\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     20774\n",
      "   macro avg       0.29      0.47      0.28     20774\n",
      "weighted avg       0.90      0.61      0.71     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.08      0.16      0.10      1456\n",
      "       Italy       0.14      0.22      0.17      2429\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.81      0.60      0.69     16889\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20774\n",
      "   macro avg       0.26      0.24      0.24     20774\n",
      "weighted avg       0.68      0.52      0.59     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.04      0.55      0.08       238\n",
      "       Italy       0.00      0.83      0.00         6\n",
      "       Spain       0.00      0.57      0.01        14\n",
      "          US       1.00      0.61      0.75     20516\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.26      0.64      0.21     20774\n",
      "weighted avg       0.98      0.60      0.74     20774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
