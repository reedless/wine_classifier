{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
       "\n",
       "              variety  \n",
       "0  Cabernet Sauvignon  \n",
       "1       Tinta de Toro  \n",
       "2     Sauvignon Blanc  \n",
       "3          Pinot Noir  \n",
       "4  Provence red blend  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out features X and labels y\n",
    "X = df.iloc[:,2:4].values\n",
    "y = df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 96., 235.],\n",
       "        [ 96., 110.],\n",
       "        [ 96.,  90.],\n",
       "        ...,\n",
       "        [ 91.,  20.],\n",
       "        [ 90.,  52.],\n",
       "        [ 90.,  15.]]), 0        US\n",
       " 1     Spain\n",
       " 2        US\n",
       " 3        US\n",
       " 4    France\n",
       " Name: country, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91. 60.]\n",
      " [84. 13.]\n",
      " [87. 26.]\n",
      " ...\n",
      " [87. 28.]\n",
      " [90. 26.]\n",
      " [93. 55.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17649      Spain\n",
       "87040         US\n",
       "44300         US\n",
       "101288    France\n",
       "81544      Italy\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise models\n",
    "LR_model         = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "LDA_model        = LinearDiscriminantAnalysis()\n",
    "KNN_model        = KNeighborsClassifier()\n",
    "GaussianNB_model = GaussianNB()\n",
    "DTree_model      = DecisionTreeClassifier()\n",
    "SVC_model        = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(booster='gbtree', objective='multi:softprob', random_state=42, eval_metric=\"auc\", num_class=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition of scaling here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, eval_metric='auc', gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, num_class=4, objective='multi:softprob',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for evaluation\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(X_test)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(X_test)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(X_test)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(X_test)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(X_test)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(X_test)\n",
    "list_of_predictions.append(SVC_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_prediction   = xgb_model.predict(X_test)\n",
    "list_of_predictions.append(XGB_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16621738711851353\n",
      "0.16159622605179552\n",
      "0.16313661307403485\n",
      "0.31707904110907864\n",
      "0.14782901704053145\n",
      "0.17170501588524117\n",
      "0.1425820737460287\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US        12461\n",
       "Italy      3724\n",
       "France     2958\n",
       "Spain      1631\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1225 1496  328 5281]\n",
      " [1733 2228 1303 7180]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]]\n",
      "[[1431 1798  417 6627]\n",
      " [1527 1926 1214 5834]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]]\n",
      "[[1801 2194  583 8352]\n",
      " [1142 1515 1011 4036]\n",
      " [   0    0    0    0]\n",
      " [  15   15   37   73]]\n",
      "[[1568 1955  479 7442]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]\n",
      " [1390 1769 1152 5019]]\n",
      "[[ 2318  2974   902 10496]\n",
      " [  640   748   728  1960]\n",
      " [    0     0     0     0]\n",
      " [    0     2     1     5]]\n",
      "[[ 894 1051  229 2961]\n",
      " [2064 2673 1402 9500]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]]\n",
      "[[ 2950  3712  1607 12397]\n",
      " [    8    12    24    64]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.41      0.15      0.22      8330\n",
      "       Italy       0.60      0.18      0.28     12444\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.17      0.17      0.17     20774\n",
      "   macro avg       0.25      0.08      0.12     20774\n",
      "weighted avg       0.52      0.17      0.25     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.48      0.14      0.22     10273\n",
      "       Italy       0.52      0.18      0.27     10501\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     20774\n",
      "   macro avg       0.25      0.08      0.12     20774\n",
      "weighted avg       0.50      0.16      0.24     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.61      0.14      0.23     12930\n",
      "       Italy       0.41      0.20      0.27      7704\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.01      0.52      0.01       140\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     20774\n",
      "   macro avg       0.26      0.21      0.13     20774\n",
      "weighted avg       0.53      0.16      0.24     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.53      0.14      0.22     11444\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.40      0.54      0.46      9330\n",
      "\n",
      "   micro avg       0.32      0.32      0.32     20774\n",
      "   macro avg       0.23      0.17      0.17     20774\n",
      "weighted avg       0.47      0.32      0.33     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.78      0.14      0.24     16690\n",
      "       Italy       0.20      0.18      0.19      4076\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.00      0.62      0.00         8\n",
      "\n",
      "   micro avg       0.15      0.15      0.15     20774\n",
      "   macro avg       0.25      0.24      0.11     20774\n",
      "weighted avg       0.67      0.15      0.23     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.30      0.17      0.22      5135\n",
      "       Italy       0.72      0.17      0.28     15639\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.17      0.17      0.17     20774\n",
      "   macro avg       0.26      0.09      0.12     20774\n",
      "weighted avg       0.62      0.17      0.26     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       1.00      0.14      0.25     20666\n",
      "       Italy       0.00      0.11      0.01       108\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     20774\n",
      "   macro avg       0.25      0.06      0.06     20774\n",
      "weighted avg       0.99      0.14      0.25     20774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
