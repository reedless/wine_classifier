{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
       "\n",
       "              variety  \n",
       "0  Cabernet Sauvignon  \n",
       "1       Tinta de Toro  \n",
       "2     Sauvignon Blanc  \n",
       "3          Pinot Noir  \n",
       "4  Provence red blend  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103868, 5), (103868, 5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "      <th>variety_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
       "\n",
       "              variety  variety_id  \n",
       "0  Cabernet Sauvignon           0  \n",
       "1       Tinta de Toro           1  \n",
       "2     Sauvignon Blanc           2  \n",
       "3          Pinot Noir           3  \n",
       "4  Provence red blend           4  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['variety_id'] = df['variety'].factorize()[0]\n",
    "\n",
    "variety_id_df = df[['price', 'variety_id']].drop_duplicates().sort_values('variety_id')\n",
    "variety_to_id = dict(variety_id_df.values)\n",
    "id_to_variety = dict(variety_id_df[['variety_id', 'price']].values)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103868, 233)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 gives 2363, 200 gives 1542, 500 gives 764, 1000 gives 416, 2000 gives 233\n",
    "tfidf = TfidfVectorizer(min_df=2000, stop_words='english')\n",
    "features = tfidf.fit_transform(df.description)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.SparseDataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.134655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173996</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.411407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2         3    4    5    6    7    8         9    ...  223  \\\n",
       "0       NaN  NaN  NaN       NaN  NaN  NaN  NaN  NaN  NaN       NaN  ...  NaN   \n",
       "1       NaN  NaN  NaN       NaN  NaN  NaN  NaN  NaN  NaN  0.173599  ...  NaN   \n",
       "2       NaN  NaN  NaN       NaN  NaN  NaN  NaN  NaN  NaN       NaN  ...  NaN   \n",
       "3       NaN  NaN  NaN       NaN  NaN  NaN  NaN  NaN  NaN  0.173996  ...  NaN   \n",
       "4  0.206754  NaN  NaN  0.357698  NaN  NaN  NaN  NaN  NaN       NaN  ...  NaN   \n",
       "\n",
       "        224  225       226  227  228       229  230      231  232  \n",
       "0       NaN  NaN  0.118902  NaN  NaN       NaN  NaN  0.48106  NaN  \n",
       "1       NaN  NaN       NaN  NaN  NaN       NaN  NaN      NaN  NaN  \n",
       "2  0.283014  NaN  0.134655  NaN  NaN       NaN  NaN      NaN  NaN  \n",
       "3       NaN  NaN       NaN  NaN  NaN       NaN  NaN      NaN  NaN  \n",
       "4       NaN  NaN  0.411407  NaN  NaN  0.347364  NaN      NaN  NaN  \n",
       "\n",
       "[5 rows x 233 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf_filled = sdf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(sdf_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "      <th>variety_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>4</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
       "\n",
       "              variety  variety_id         0    1    2         3  ...  223  \\\n",
       "0  Cabernet Sauvignon           0  0.000000  0.0  0.0  0.000000  ...  0.0   \n",
       "1       Tinta de Toro           1  0.000000  0.0  0.0  0.000000  ...  0.0   \n",
       "2     Sauvignon Blanc           2  0.000000  0.0  0.0  0.000000  ...  0.0   \n",
       "3          Pinot Noir           3  0.000000  0.0  0.0  0.000000  ...  0.0   \n",
       "4  Provence red blend           4  0.206754  0.0  0.0  0.357698  ...  0.0   \n",
       "\n",
       "        224  225       226  227  228       229  230      231  232  \n",
       "0  0.000000  0.0  0.118902  0.0  0.0  0.000000  0.0  0.48106  0.0  \n",
       "1  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.00000  0.0  \n",
       "2  0.283014  0.0  0.134655  0.0  0.0  0.000000  0.0  0.00000  0.0  \n",
       "3  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.00000  0.0  \n",
       "4  0.000000  0.0  0.411407  0.0  0.0  0.347364  0.0  0.00000  0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick out features X and labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['country', 'description', 'variety']).values\n",
    "y = df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[96, 235.0, 0, ..., 0.0, 0.48106018323469013, 0.0],\n",
       "        [96, 110.0, 1, ..., 0.0, 0.0, 0.0],\n",
       "        [96, 90.0, 2, ..., 0.0, 0.0, 0.0],\n",
       "        ...,\n",
       "        [91, 20.0, 34, ..., 0.0, 0.0, 0.0],\n",
       "        [90, 52.0, 78, ..., 0.0, 0.0, 0.0],\n",
       "        [90, 15.0, 32, ..., 0.0, 0.0, 0.0]], dtype=object), 0        US\n",
       " 1     Spain\n",
       " 2        US\n",
       " 3        US\n",
       " 4    France\n",
       " Name: country, dtype: object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91 38.0 7 ... 0.0 0.0 0.0]\n",
      " [89 50.0 40 ... 0.35021814397275164 0.0 0.0]\n",
      " [87 38.0 93 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [83 14.0 210 ... 0.0 0.0 0.0]\n",
      " [86 30.0 36 ... 0.0 0.222452932550563 0.0]\n",
      " [83 38.0 12 ... 0.0 0.0 0.0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102104        US\n",
       "39339         US\n",
       "57198         US\n",
       "28598      Italy\n",
       "85027     France\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise models\n",
    "LR_model         = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "LDA_model        = LinearDiscriminantAnalysis()\n",
    "KNN_model        = KNeighborsClassifier()\n",
    "GaussianNB_model = GaussianNB()\n",
    "DTree_model      = DecisionTreeClassifier()\n",
    "SVC_model        = LinearSVC(multi_class='ovr')\n",
    "xgb_model        = XGBClassifier(booster='gbtree', objective='multi:softprob', random_state=42, eval_metric=\"auc\", num_class=4)\n",
    "RandFC_model     = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, eval_metric='auc', gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, num_class=4, objective='multi:softprob',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandFC_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_test\n",
    "test_labels = y_test\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(test_set)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(test_set)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(test_set)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(test_set)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(test_set)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(test_set)\n",
    "list_of_predictions.append(SVC_prediction)\n",
    "\n",
    "XGB_prediction   = xgb_model.predict(test_set)\n",
    "list_of_predictions.append(XGB_prediction)\n",
    "\n",
    "RandFC_prediction = RandFC_model.predict(test_set)\n",
    "list_of_predictions.append(RandFC_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8556849908539521\n",
      "0.86049870029845\n",
      "0.8297230512499599\n",
      "0.7057860787522865\n",
      "0.9070312249285967\n",
      "0.8124578800423606\n",
      "0.8585732165206508\n",
      "0.7626199415936588\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3139   135    84   430]\n",
      " [  168  4690   172   526]\n",
      " [  103   181  1463   256]\n",
      " [ 1044   662   736 17372]]\n",
      "[[ 3140   116    62   398]\n",
      " [  128  4569   105   385]\n",
      " [  167   240  1757   453]\n",
      " [ 1019   743   531 17348]]\n",
      "[[ 2842   140   164   822]\n",
      " [  203  4737   246   854]\n",
      " [   78   111  1636   268]\n",
      " [ 1331   680   409 16640]]\n",
      "[[ 3418   253   144  1777]\n",
      " [  251  4388   144  1397]\n",
      " [  479   722  2012  3235]\n",
      " [  306   305   155 12175]]\n",
      "[[ 3726    86    41   587]\n",
      " [  101  5115    91   488]\n",
      " [   57    93  2111   197]\n",
      " [  570   374   212 17312]]\n",
      "[[ 2997   242    62   291]\n",
      " [   48  2814    34   101]\n",
      " [  106   768  1562   248]\n",
      " [ 1303  1844   797 17944]]\n",
      "[[ 2533    57    53   136]\n",
      " [  152  4563   157   371]\n",
      " [   81    98  1688   107]\n",
      " [ 1688   950   557 17970]]\n",
      "[[  997     0     0     4]\n",
      " [   74  3677   108   142]\n",
      " [   16    21   662    10]\n",
      " [ 3367  1970  1685 18428]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.70      0.83      0.76      3788\n",
      "       Italy       0.83      0.84      0.84      5556\n",
      "       Spain       0.60      0.73      0.66      2003\n",
      "          US       0.93      0.88      0.90     19814\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     31161\n",
      "   macro avg       0.77      0.82      0.79     31161\n",
      "weighted avg       0.87      0.86      0.86     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.70      0.84      0.77      3716\n",
      "       Italy       0.81      0.88      0.84      5187\n",
      "       Spain       0.72      0.67      0.69      2617\n",
      "          US       0.93      0.88      0.91     19641\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     31161\n",
      "   macro avg       0.79      0.82      0.80     31161\n",
      "weighted avg       0.87      0.86      0.86     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.64      0.72      0.67      3968\n",
      "       Italy       0.84      0.78      0.81      6040\n",
      "       Spain       0.67      0.78      0.72      2093\n",
      "          US       0.90      0.87      0.88     19060\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     31161\n",
      "   macro avg       0.76      0.79      0.77     31161\n",
      "weighted avg       0.84      0.83      0.83     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.77      0.61      0.68      5592\n",
      "       Italy       0.77      0.71      0.74      6180\n",
      "       Spain       0.82      0.31      0.45      6448\n",
      "          US       0.66      0.94      0.77     12941\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     31161\n",
      "   macro avg       0.75      0.64      0.66     31161\n",
      "weighted avg       0.73      0.71      0.68     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.84      0.84      0.84      4440\n",
      "       Italy       0.90      0.88      0.89      5795\n",
      "       Spain       0.86      0.86      0.86      2458\n",
      "          US       0.93      0.94      0.93     18468\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     31161\n",
      "   macro avg       0.88      0.88      0.88     31161\n",
      "weighted avg       0.91      0.91      0.91     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.67      0.83      0.74      3592\n",
      "       Italy       0.50      0.94      0.65      2997\n",
      "       Spain       0.64      0.58      0.61      2684\n",
      "          US       0.97      0.82      0.89     21888\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     31161\n",
      "   macro avg       0.69      0.79      0.72     31161\n",
      "weighted avg       0.86      0.81      0.82     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.57      0.91      0.70      2779\n",
      "       Italy       0.81      0.87      0.84      5243\n",
      "       Spain       0.69      0.86      0.76      1974\n",
      "          US       0.97      0.85      0.90     21165\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     31161\n",
      "   macro avg       0.76      0.87      0.80     31161\n",
      "weighted avg       0.89      0.86      0.87     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.22      1.00      0.37      1001\n",
      "       Italy       0.65      0.92      0.76      4001\n",
      "       Spain       0.27      0.93      0.42       709\n",
      "          US       0.99      0.72      0.84     25450\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     31161\n",
      "   macro avg       0.53      0.89      0.60     31161\n",
      "weighted avg       0.91      0.76      0.80     31161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_train\n",
    "test_labels = y_train\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(test_set)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(test_set)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(test_set)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(test_set)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(test_set)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(test_set)\n",
    "list_of_predictions.append(SVC_prediction)\n",
    "\n",
    "XGB_prediction   = xgb_model.predict(test_set)\n",
    "list_of_predictions.append(XGB_prediction)\n",
    "\n",
    "RandFC_prediction = RandFC_model.predict(test_set)\n",
    "list_of_predictions.append(RandFC_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6011938327808877\n",
      "0.6015101709601551\n",
      "0.5401955795177906\n",
      "0.5974252822974404\n",
      "0.6223472292901646\n",
      "0.46266521792949783\n",
      "0.6046047835834238\n",
      "0.6093361024385547\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US        18584\n",
       "Italy      5668\n",
       "France     4454\n",
       "Spain      2455\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  183    59    11    27]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [10148 13057  5694 43528]]\n",
      "[[  242    90    23    63]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [10089 13026  5682 43492]]\n",
      "[[ 2503  1942   802  3967]\n",
      " [ 1593  2851  1021  4716]\n",
      " [  475   501   696  1646]\n",
      " [ 5760  7822  3186 33226]]\n",
      "[[ 1004   708   209  1101]\n",
      " [   53    86    18   107]\n",
      " [    0     0     0     0]\n",
      " [ 9274 12322  5478 42347]]\n",
      "[[ 1187   296   111   327]\n",
      " [  509  1576   221   871]\n",
      " [   42    59   242   113]\n",
      " [ 8593 11185  5131 42244]]\n",
      "[[    0     0     0     0]\n",
      " [ 3430  3796  1568 13712]\n",
      " [    0     0     0     0]\n",
      " [ 6901  9320  4137 29843]]\n",
      "[[  532   235    98   169]\n",
      " [   12    33     2     7]\n",
      " [    1     6    31    16]\n",
      " [ 9786 12842  5574 43363]]\n",
      "[[  649   226   114   211]\n",
      " [  134   459    56   200]\n",
      " [   36    57   149    98]\n",
      " [ 9512 12374  5386 43046]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.01      0.68      0.03        65\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     20709\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.25      0.32      0.20     20774\n",
      "weighted avg       1.00      0.60      0.75     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.02      0.56      0.04       102\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     20672\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.25      0.29      0.20     20774\n",
      "weighted avg       0.99      0.60      0.75     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.18      0.27      0.22      1993\n",
      "       Italy       0.21      0.29      0.25      2711\n",
      "       Spain       0.08      0.17      0.11       745\n",
      "          US       0.80      0.65      0.71     15325\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     20774\n",
      "   macro avg       0.32      0.34      0.32     20774\n",
      "weighted avg       0.64      0.55      0.58     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.10      0.36      0.16       805\n",
      "       Italy       0.01      0.34      0.01        79\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.61      0.75     19890\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.27      0.33      0.23     20774\n",
      "weighted avg       0.94      0.60      0.72     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.08      0.51      0.14       488\n",
      "       Italy       0.09      0.41      0.15       821\n",
      "       Spain       0.03      0.33      0.06       165\n",
      "          US       0.97      0.62      0.76     19300\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     20774\n",
      "   macro avg       0.29      0.47      0.28     20774\n",
      "weighted avg       0.90      0.61      0.71     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.08      0.16      0.10      1456\n",
      "       Italy       0.14      0.22      0.17      2429\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.81      0.60      0.69     16889\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20774\n",
      "   macro avg       0.26      0.24      0.24     20774\n",
      "weighted avg       0.68      0.52      0.59     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.04      0.55      0.08       238\n",
      "       Italy       0.00      0.83      0.00         6\n",
      "       Spain       0.00      0.57      0.01        14\n",
      "          US       1.00      0.61      0.75     20516\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.26      0.64      0.21     20774\n",
      "weighted avg       0.98      0.60      0.74     20774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
