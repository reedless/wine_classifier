{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  points  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
       "\n",
       "              variety  \n",
       "0  Cabernet Sauvignon  \n",
       "1       Tinta de Toro  \n",
       "2     Sauvignon Blanc  \n",
       "3          Pinot Noir  \n",
       "4  Provence red blend  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103868, 5), (103868, 5))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "      <th>variety_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spain</td>\n",
       "      <td>95</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>95</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spain</td>\n",
       "      <td>95</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Italy</td>\n",
       "      <td>95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Friulano</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>France</td>\n",
       "      <td>95</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Tannat</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>325.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spain</td>\n",
       "      <td>95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>France</td>\n",
       "      <td>95</td>\n",
       "      <td>290.0</td>\n",
       "      <td>Malbec</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>US</td>\n",
       "      <td>95</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  points  price             variety  variety_id\n",
       "0       US      96  235.0  Cabernet Sauvignon           0\n",
       "1    Spain      96  110.0       Tinta de Toro           1\n",
       "2       US      96   90.0     Sauvignon Blanc           2\n",
       "3       US      96   65.0          Pinot Noir           3\n",
       "4   France      95   66.0  Provence red blend           4\n",
       "5    Spain      95   73.0       Tinta de Toro           1\n",
       "6    Spain      95   65.0       Tinta de Toro           1\n",
       "7    Spain      95  110.0       Tinta de Toro           1\n",
       "8       US      95   65.0          Pinot Noir           3\n",
       "9       US      95   60.0          Pinot Noir           3\n",
       "10   Italy      95   80.0            Friulano           5\n",
       "11      US      95   48.0          Pinot Noir           3\n",
       "12      US      95   48.0          Pinot Noir           3\n",
       "13  France      95   90.0              Tannat           6\n",
       "14      US      95  185.0          Pinot Noir           3\n",
       "15      US      95   90.0          Chardonnay           7\n",
       "16      US      95  325.0  Cabernet Sauvignon           0\n",
       "17   Spain      95   80.0         Tempranillo           8\n",
       "18  France      95  290.0              Malbec           9\n",
       "19      US      95   75.0          Pinot Noir           3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['country', 'points', 'price', 'variety']\n",
    "df = df[col]\n",
    "df['variety_id'] = df['variety'].factorize()[0]\n",
    "\n",
    "variety_id_df = df[['price', 'variety_id']].drop_duplicates().sort_values('variety_id')\n",
    "variety_to_id = dict(variety_id_df.values)\n",
    "id_to_variety = dict(variety_id_df[['variety_id', 'price']].values)\n",
    "\n",
    "df.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick out features X and labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['points', 'price', 'variety_id']].values\n",
    "y = df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 96., 235.,   0.],\n",
       "        [ 96., 110.,   1.],\n",
       "        [ 96.,  90.,   2.],\n",
       "        ...,\n",
       "        [ 91.,  20.,  34.],\n",
       "        [ 90.,  52.,  78.],\n",
       "        [ 90.,  15.,  32.]]), 0        US\n",
       " 1     Spain\n",
       " 2        US\n",
       " 3        US\n",
       " 4    France\n",
       " Name: country, dtype: object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91.  38.   7.]\n",
      " [ 89.  50.  40.]\n",
      " [ 87.  38.  93.]\n",
      " ...\n",
      " [ 83.  14. 210.]\n",
      " [ 86.  30.  36.]\n",
      " [ 83.  38.  12.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102104        US\n",
       "39339         US\n",
       "57198         US\n",
       "28598      Italy\n",
       "85027     France\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise models\n",
    "LR_model         = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "LDA_model        = LinearDiscriminantAnalysis()\n",
    "KNN_model        = KNeighborsClassifier()\n",
    "GaussianNB_model = GaussianNB()\n",
    "DTree_model      = DecisionTreeClassifier()\n",
    "SVC_model        = LinearSVC(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(booster='gbtree', objective='multi:softprob', random_state=42, eval_metric=\"auc\", num_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandFC_model = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, eval_metric='auc', gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, num_class=4, objective='multi:softprob',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandFC_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_test\n",
    "test_labels = y_test\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(test_set)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(test_set)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(test_set)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(test_set)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(test_set)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(test_set)\n",
    "list_of_predictions.append(SVC_prediction)\n",
    "\n",
    "XGB_prediction   = xgb_model.predict(test_set)\n",
    "list_of_predictions.append(XGB_prediction)\n",
    "\n",
    "RandFC_prediction = RandFC_model.predict(test_set)\n",
    "list_of_predictions.append(RandFC_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6330990661403678\n",
      "0.6337408940663009\n",
      "0.7867847630050383\n",
      "0.6298899265107025\n",
      "0.8386444594204294\n",
      "0.6289913674143962\n",
      "0.7719585379159847\n",
      "0.7235005295080389\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   89    22     6    17]\n",
      " [  171  1564   262   492]\n",
      " [    0     0     0     0]\n",
      " [ 4194  4082  2187 18075]]\n",
      "[[  112    29    11    30]\n",
      " [  149  1573   263   491]\n",
      " [    0     0     0     0]\n",
      " [ 4193  4066  2181 18063]]\n",
      "[[ 2390   179   221  1008]\n",
      " [  213  4430   277  1023]\n",
      " [  100   131  1454   310]\n",
      " [ 1751   928   503 16243]]\n",
      "[[  422   201    85   446]\n",
      " [  184  1584   319   519]\n",
      " [    9     7    35    32]\n",
      " [ 3839  3876  2016 17587]]\n",
      "[[ 2821    84    72   902]\n",
      " [   97  4761   159   801]\n",
      " [   43    77  1914   244]\n",
      " [ 1493   746   310 16637]]\n",
      "[[    0     0     0     0]\n",
      " [  220  1616   426   600]\n",
      " [    0     0     0     0]\n",
      " [ 4234  4052  2029 17984]]\n",
      "[[ 1613    63   136   379]\n",
      " [  155  3972   284   848]\n",
      " [   45    18  1279   166]\n",
      " [ 2641  1615   756 17191]]\n",
      "[[  957    53    83   146]\n",
      " [  198  2833   240   527]\n",
      " [   45    19   958   114]\n",
      " [ 3254  2763  1174 17797]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.02      0.66      0.04       134\n",
      "       Italy       0.28      0.63      0.38      2489\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.63      0.77     28538\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     31161\n",
      "   macro avg       0.32      0.48      0.30     31161\n",
      "weighted avg       0.91      0.63      0.73     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.03      0.62      0.05       182\n",
      "       Italy       0.28      0.64      0.39      2476\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.63      0.77     28503\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     31161\n",
      "   macro avg       0.32      0.47      0.30     31161\n",
      "weighted avg       0.91      0.63      0.73     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.54      0.63      0.58      3798\n",
      "       Italy       0.78      0.75      0.76      5943\n",
      "       Spain       0.59      0.73      0.65      1995\n",
      "          US       0.87      0.84      0.85     19425\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     31161\n",
      "   macro avg       0.70      0.73      0.71     31161\n",
      "weighted avg       0.80      0.79      0.79     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.09      0.37      0.15      1154\n",
      "       Italy       0.28      0.61      0.38      2606\n",
      "       Spain       0.01      0.42      0.03        83\n",
      "          US       0.95      0.64      0.77     27318\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     31161\n",
      "   macro avg       0.33      0.51      0.33     31161\n",
      "weighted avg       0.86      0.63      0.71     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.63      0.73      0.68      3879\n",
      "       Italy       0.84      0.82      0.83      5818\n",
      "       Spain       0.78      0.84      0.81      2278\n",
      "          US       0.90      0.87      0.88     19186\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     31161\n",
      "   macro avg       0.79      0.81      0.80     31161\n",
      "weighted avg       0.84      0.84      0.84     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.00      0.00      0.00         0\n",
      "       Italy       0.29      0.56      0.38      2862\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.64      0.77     28299\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     31161\n",
      "   macro avg       0.31      0.30      0.29     31161\n",
      "weighted avg       0.91      0.63      0.73     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.36      0.74      0.49      2191\n",
      "       Italy       0.70      0.76      0.73      5259\n",
      "       Spain       0.52      0.85      0.65      1508\n",
      "          US       0.93      0.77      0.84     22203\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     31161\n",
      "   macro avg       0.63      0.78      0.68     31161\n",
      "weighted avg       0.83      0.77      0.79     31161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.21      0.77      0.34      1239\n",
      "       Italy       0.50      0.75      0.60      3798\n",
      "       Spain       0.39      0.84      0.53      1136\n",
      "          US       0.96      0.71      0.82     24988\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     31161\n",
      "   macro avg       0.52      0.77      0.57     31161\n",
      "weighted avg       0.85      0.72      0.76     31161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_train\n",
    "test_labels = y_train\n",
    "list_of_predictions = []\n",
    "\n",
    "LR_prediction    = LR_model.predict(test_set)\n",
    "list_of_predictions.append(LR_prediction)\n",
    "\n",
    "LDA_prediction   = LDA_model.predict(test_set)\n",
    "list_of_predictions.append(LDA_prediction)\n",
    "\n",
    "KNN_prediction   = KNN_model.predict(test_set)\n",
    "list_of_predictions.append(KNN_prediction)\n",
    "\n",
    "GNB_prediction   = GaussianNB_model.predict(test_set)\n",
    "list_of_predictions.append(GNB_prediction)\n",
    "\n",
    "DTree_prediction = DTree_model.predict(test_set)\n",
    "list_of_predictions.append(DTree_prediction)\n",
    "\n",
    "SVC_prediction   = SVC_model.predict(test_set)\n",
    "list_of_predictions.append(SVC_prediction)\n",
    "\n",
    "XGB_prediction   = xgb_model.predict(test_set)\n",
    "list_of_predictions.append(XGB_prediction)\n",
    "\n",
    "RandFC_prediction = RandFC_model.predict(test_set)\n",
    "list_of_predictions.append(RandFC_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6011938327808877\n",
      "0.6015101709601551\n",
      "0.5401955795177906\n",
      "0.5974252822974404\n",
      "0.6223472292901646\n",
      "0.46266521792949783\n",
      "0.6046047835834238\n",
      "0.6093361024385547\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate\n",
    "for prediction in list_of_predictions:\n",
    "    print(accuracy_score(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US        18584\n",
       "Italy      5668\n",
       "France     4454\n",
       "Spain      2455\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  183    59    11    27]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [10148 13057  5694 43528]]\n",
      "[[  242    90    23    63]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [10089 13026  5682 43492]]\n",
      "[[ 2503  1942   802  3967]\n",
      " [ 1593  2851  1021  4716]\n",
      " [  475   501   696  1646]\n",
      " [ 5760  7822  3186 33226]]\n",
      "[[ 1004   708   209  1101]\n",
      " [   53    86    18   107]\n",
      " [    0     0     0     0]\n",
      " [ 9274 12322  5478 42347]]\n",
      "[[ 1187   296   111   327]\n",
      " [  509  1576   221   871]\n",
      " [   42    59   242   113]\n",
      " [ 8593 11185  5131 42244]]\n",
      "[[    0     0     0     0]\n",
      " [ 3430  3796  1568 13712]\n",
      " [    0     0     0     0]\n",
      " [ 6901  9320  4137 29843]]\n",
      "[[  532   235    98   169]\n",
      " [   12    33     2     7]\n",
      " [    1     6    31    16]\n",
      " [ 9786 12842  5574 43363]]\n",
      "[[  649   226   114   211]\n",
      " [  134   459    56   200]\n",
      " [   36    57   149    98]\n",
      " [ 9512 12374  5386 43046]]\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(confusion_matrix(prediction, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reedless/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.01      0.68      0.03        65\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     20709\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.25      0.32      0.20     20774\n",
      "weighted avg       1.00      0.60      0.75     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.02      0.56      0.04       102\n",
      "       Italy       0.00      0.00      0.00         0\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       1.00      0.60      0.75     20672\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.25      0.29      0.20     20774\n",
      "weighted avg       0.99      0.60      0.75     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.18      0.27      0.22      1993\n",
      "       Italy       0.21      0.29      0.25      2711\n",
      "       Spain       0.08      0.17      0.11       745\n",
      "          US       0.80      0.65      0.71     15325\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     20774\n",
      "   macro avg       0.32      0.34      0.32     20774\n",
      "weighted avg       0.64      0.55      0.58     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.10      0.36      0.16       805\n",
      "       Italy       0.01      0.34      0.01        79\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.97      0.61      0.75     19890\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.27      0.33      0.23     20774\n",
      "weighted avg       0.94      0.60      0.72     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.08      0.51      0.14       488\n",
      "       Italy       0.09      0.41      0.15       821\n",
      "       Spain       0.03      0.33      0.06       165\n",
      "          US       0.97      0.62      0.76     19300\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     20774\n",
      "   macro avg       0.29      0.47      0.28     20774\n",
      "weighted avg       0.90      0.61      0.71     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.08      0.16      0.10      1456\n",
      "       Italy       0.14      0.22      0.17      2429\n",
      "       Spain       0.00      0.00      0.00         0\n",
      "          US       0.81      0.60      0.69     16889\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     20774\n",
      "   macro avg       0.26      0.24      0.24     20774\n",
      "weighted avg       0.68      0.52      0.59     20774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.04      0.55      0.08       238\n",
      "       Italy       0.00      0.83      0.00         6\n",
      "       Spain       0.00      0.57      0.01        14\n",
      "          US       1.00      0.61      0.75     20516\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     20774\n",
      "   macro avg       0.26      0.64      0.21     20774\n",
      "weighted avg       0.98      0.60      0.74     20774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report for all predictions\n",
    "for prediction in list_of_predictions:\n",
    "    print(classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
